#!/usr/bin/env python3

# Copyright 2020 Regents of The University of Michigan.

# This file is part of geo-omics-scripts.

# Geo-omics-scripts is free software: you can redistribute it and/or
# modify it under the terms of the GNU General Public License as published
# by the Free Software Foundation, either version 3 of the License, or (at
# your option) any later version.

# Geo-omics-scripts is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.

# You should have received a copy of the GNU General Public License along
# with Geo-omics-scripts.  If not, see <https://www.gnu.org/licenses/>.

"""
Conditionally select samples and OTUs from shared file based on meta data
"""
import argparse
from pathlib import Path
import sys

import pandas

from omics.shared import MothurShared


def info(*args, **kwargs):
    print(*args, file=sys.stdout, **kwargs)


argp = argparse.ArgumentParser(description=__doc__)
argp.add_argument(
    'query',
    nargs='*',
    help='One or more query specifications of the form <column>[!]=<field>',
)
argp.add_argument(
    'shared_file',
    type=argparse.FileType(),
    help='Mothur shared file',
)
argp.add_argument(
    '-s', '--min-sample-size',
    type=int,
    default=0,
    help='Remove samples with a read count lower than this.  A value lower '
         'than 1 has no effect.  The default is to not apply a cutoff.',
)
argp.add_argument(
    '-m', '--meta-data',
    type=argparse.FileType(),
    default=None,
    help='Tab-separated table with meta data with header row with column '
         'names, and one row per sample, first column must be sample names',
)
argp.add_argument(
    '--force-prefix-matching',
    action='store_true',
    help='This script need to match the sample names from the meta data to '
         'the names from the shared file.  If there is no overlap at all by '
         'exact string matching, the script will first see if substituting '
         'dashes for underscore in the meta data samples will produce any '
         'exact matches.  If that fails prefix matching will be attempted, so '
         'the names in the meta data need to uniquely match the beginning of '
         'a name in the shared file.  This option forces prefix matching, '
         'even if there are some exact matches already.',
)
argp.add_argument(
    '-o', '--output',
    help='Name of output file.  If not given, a filename will be generated',
)
argp.add_argument(
    '-t', '--threads',
    type=int,
    default=1,
    help='Number of threads to use for parallizable steps',
)
argp.add_argument('--version', action='version', version='%(prog)s '
                  'is part of geo-omics-scripts VERSION_PLACEHOLDER')
args = argp.parse_args()

if args.output is None:
    outfile = Path(Path(args.shared_file.name).name)
    outfile = outfile.with_suffix('.pick.shared')
else:
    outfile = args.output

if args.meta_data is None:
    meta = None
else:
    meta = pandas.read_table(args.meta_data, index_col=0, dtype=str,
                             keep_default_na=False)

    info('Loaded meta data for {} samples'.format(len(meta.index)))

# parse query specs
query = []
anti_query = []
for i in args.query:
    try:
        key, val = i.split('!=')
    except ValueError:
        try:
            key, val = i.split('=')
        except ValueError:
            argp.error('Failed to parse selection query : {}'.format(i))
        else:
            query.append((key, val))
    else:
        anti_query.append((key, val))

    if key not in meta.columns:
        argp.error('query key {} is not a column in the meta data table'
                   ''.format(key))

# compute selection
for key, val in query:
    meta = meta[meta[key] == val]

for key, val in anti_query:
    meta = meta[meta[key] != val]

if meta is not None:
    info('Samples matching query:', len(meta.index))

info('Loading shared file...')
sh = MothurShared(args.shared_file, threads=args.threads)
if meta is None:
    samples = sh.samples
else:
    samples = None
    if set(sh.samples).isdisjoint(meta.index) or args.force_prefix_matching:
        if not args.force_prefix_matching:
            info('Sample names in shared file don\'t match sample names in '
                 'meta data at all!')
        mchrs = set(''.join(meta.index))
        schrs = set(''.join(sh.samples))
        if '-' in mchrs and '_' in schrs and '-' not in schrs:
            # think: shared samples conform to mothur group names
            info('Converting meta data samples to match mothur '
                 'expectations (s/-/_/g) ...')
            meta.index = map(lambda x: x.replace('-', '_'), meta.index)

        if set(sh.samples).isdisjoint(meta.index) \
                or args.force_prefix_matching:
            # try unique prefix matching, e.g. if shared samples have S-number
            # attached
            # NOTE: only considering meta samples matching the query
            pref_map = {}
            for i in sh.samples:
                for j in sorted(meta.index, key=lambda x: -len(x)):
                    if i.startswith(j):
                        pref_map[i] = j
                        break
            if len(set(pref_map.values())) < len(pref_map):
                # multiple meta data samples map to same shared sample
                argp.error('Failed to uniquely match meta data sample names '
                           'to shared file via matching prefixes')
            samples = list(pref_map.keys())
            if not samples:
                argp.error(
                    'Also failed to match up any samples in shared file with '
                    'any sample in the meta data via prefix matching'
                )

    if samples is None:
        # do exact matching
        samples = [i for i in meta.index if i in sh.samples]

if args.min_sample_size > 0:
    big = sh.counts.sum(axis=1) >= args.min_sample_size
    big_samples = sh.counts[big].index
    print(big_samples)
    info('samples above minimum size:', len(big_samples))
    samples = [i for i in samples if i in big_samples]

info('Matching samples present in shared file:', len(samples))
info('Selecting subset...')
sh.pick_samples(samples)
info('Writing output... ', end='', flush=True)
sh.save(outfile)
info('saved as:', outfile)
