#!/bin/bash
#
# Copyright (c) 2017 Regents of The University of Michigan.
# All Rights Reserved.
#
# Author: Robert <heinro@med.umich.edu>
#

set -ueEo pipefail
RESOURCE_DIR=$(dirname "$0")/../share/geo-omics-scripts

# shellcheck disable=SC2034
{
USAGE="[OPTIONS]..."
HELP="quality control for a sample's fastq files"
ARG_HELP="
  -f, --fwd             Fastq file name with forward reads, default is fwd.fastq.
                        A file with this name needs to be present in each sample
                        directory.
  -r, --rev             Fastq file name with reverse reads default is rev.fastq.
                        A file with this name needs to be present in each sample
                        directory.
      --final INFIX     Infix used for final output files.  Default is 'good'
      --clean-only      Delete previously created files and stop.
  -a, --adapters=FILE   Specifies the adapters file to be used.  By default a
                        file based on the Illumina adapter file TruSeq3-PE-2.fa
                        as distributed by the Trimmomatic project.
      --keep-all	Keep all intermediate files, by default some not-so-important
			intermediate results will be deleted to save disk space
      --no-dereplicate  Skip the de-replication step
      --no-fasta-interleave
                        Skip building the interleaved fasta file,
                        interleaved fastq will still be build.
  -F, --filter <trimmomatic|scythe|bbtools|derek-bbduk>
                        Choice of qc-filter.  The default is to use Trimmomatic.
                        The 'old' way of using scythe and sickle is still supported.
                        A newer alternative is to use the rqcfilter2 pipeline from
                        BBTools (bbtools) or Derek's bbduk workflow.
      --rqcfilterdata PATH
                        Path to directory containing the reference data for BBTool's rqcfilter2
                        The default is /reference-data/bbtools/RQCFilterData
  -t N, --threads N, --cpus N
                        Number of parallel threads to employ (for Trimmomatic)
"
MORE_HELP="
qc implements the QC part of the Geomicro Illumina Reads Pipline.  At each
invocation qc will clean the directory of what the script thinks are previously
generated files.

qc is part of the omics(1) tool chain.
"
SHORT_OPTIONS=a:,f:,r:,t:,F:
LONG_OPTIONS=clean-only,adapters:,filter:,fwd:,rev:,final:,keep-all,no-dereplicate,no-fasta-interleave,rqcfilterdata:,threads:,cpus:
}

handle_options () {
    if [ "$#" -gt 0 ]; then
	case "$1" in
	    (-f|--fwd)
		FWD_FASTQ=$2
		return 2;;
	    (-r|--rev)
		REV_FASTQ=$2
		return 2;;
	    (--final)
		FINAL=$2
		return 2;;
	    (-a|--adapters)
		ADAPTERS=$2
		return 2;;
	    (--clean-only)
	        CLEAN_ONLY=true
	        return 1;;
	    (--keep-all)
	        KEEPALL=true
	        return 1;;
	    (--no-dereplicate)
	        DEREPLICATION=false
	        return 1;;
	    (--no-fasta-interleave)
	        INTERLEAVE_FASTA=false
	        return 1;;
            (-F|--filter)
                FILTER=$2
                return 2;;
            (--rqcfilter-data)
                RQCFILTERDATA=$2
                return 2;;
            (-t|--threads|--cpus)
                CPUS=$2
                return 2;;
        esac
    else
        return 0
    fi
}

##########################
# default variable values
##########################

# Set adapter file depending on server (for scythe only)
ADAPTERS_DEBIAN=/usr/share/trimmomatic/TruSeq3-PE-2.fa
ADAPTERS_FLUX=/sw/lsa/centos7/trimmomatic/0.36/adapters/TruSeq3-PE-2.fa
ADAPTERS_VONDAMM=/opt/packages/Trimmomatic/0.32/adapters/TruSeq3-PE-2.fa

set_default_scythe_adapters () {
    while [ $# -gt 0 ] && [ ! -r "$1" ]; do
        shift
    done
    ADAPTERS_SCYTHE=$1
}
set_default_scythe_adapters $ADAPTERS_DEBIAN $ADAPTERS_FLUX $ADAPTERS_VONDAMM

ADAPTERS_TRIMMOMATIC=$RESOURCE_DIR/TruSeq3-PE-2+omics.fa

# default input files as produced by prep script
FWD_FASTQ=fwd.fastq
REV_FASTQ=rev.fastq
#
CLEAN_ONLY=false
# infix for final output files
FINAL=good
# Remove intermediate results by default
KEEPALL=false
#
DEREPLICATION=true
INTERLEAVE_FASTA=true
# Use Trimmomatic filtering step by default, alternatives are scythe (and sickle) and bbtools
FILTER=trimmomatic
# Default rqcfilter2 data will work on omics container
RQCFILTERDATA=/reference-data/bbtools/RQCFilterData
#
DEFAULT_CPUS=2

## shellcheck source=../lib/liba.sh
# shellcheck disable=SC1090
. "$RESOURCE_DIR/liba.sh" || (echo "Failed to source script library"; exit 1)

info1 () { info "[$(basename "$PWD")] $1" ; }
warning1 () { warning "[$(basename "$PWD")] $1" ; }
error1 () { error "[$(basename "$PWD")] $1" ; }
abort1 () { abort "[$(basename "$PWD")] $1" ; }

# mangle verbosity args
[[ -v V ]] && if [[ -n "$V" ]]; then V=("$V"); else V=(); fi

if [[ ! -v ADAPTERS ]]; then
    if [[ $FILTER == trimmomatic ]]; then
        ADAPTERS=$ADAPTERS_TRIMMOMATIC
    elif [[ $FILTER == scythe ]]; then
        ADAPTERS=$ADAPTERS_SCYTHE
    fi
fi

# use available cores on pbs job as needed
[[ -v CPUS ]] || CPUS=${PBS_NP:-$DEFAULT_CPUS}

# handle non-option parameters
if [ "$#" -gt 0 ]; then
    abort1 "Unknown parameters: ${*}"
fi

#########################
# some input sanitation
#########################
if [[ $FILTER == bbtools ]] || [[ $FILTER == derek-bbduk ]]; then
    [ -d "$RQCFILTERDATA" ] || abort1 "Reference data for rqcfilter2 not found: $RQCFILTERDATA"
elif [[ $FILTER == scythe || $FILTER == trimmomatic ]]; then
    [ -r "$ADAPTERS" ] || abort1 "Adapters file not found: $ADAPTERS"
    [ "$VERBOSITY" -lt 2 ] || info1 "Using adapters file: $ADAPTERS"
else
    abort1 "unsupported filter option: \"$FILTER\", allowed are: scythe, trimmomatic, bbtools"
fi
[ -r "$FWD_FASTQ" ] || abort1 "Forward reads file not found: $FWD_FASTQ"
[ -r "$REV_FASTQ" ] || abort1 "Reverse reads file not found: $REV_FASTQ"

#################################
# do stuff
################################

# get root of input file names
fwd=$(basename "$FWD_FASTQ" .fastq)
rev=$(basename "$REV_FASTQ" .fastq)
[ "$fwd" != "$rev" ] || abort1 "Forward and reverse reads filenames are equal?"

clean_all () {
    clean_some all
    # clean all final results
    $RM -rf -- FASTQC rqcfilter2_out
}

clean_some () {
    # only clean files that are about to be re-created in a regular run
    # TODO: add intermediate files?
    local all=false
    [[ $# -gt 0 && $1 == all ]] && all=true
    $all || info1 "Removing previously generated results..."
    $RM -rf -- FASTQC/"${fwd}"_* FASTQC/"${rev}"_*
    $RM -rf -- FASTQC/"${fwd}.${FINAL}"_* "FASTQC/${rev}.${FINAL}"_*
    $RM -f -- {int,$fwd,$rev}."$FINAL".fastq
    $INTERLEAVE_FASTA && $RM -f -- int."$FINAL".fasta
    if [[ $FILTER == scythe || $all ]]; then
       $RM -f -- {$fwd,$rev}{.derep,}.{matches,scythe}.fastq
       $RM -f -- {$fwd,$rev}.derep.fastq

    fi
    if [[ $FILTER == trimmomatic || $all ]]; then
        $RM -f -- {$fwd,$rev}{.derep,}.trim.s.fastq
        $RM -f -- {$fwd,$rev}.derep.fastq
    fi
    if [[ $FILTER == bbtools || $all ]]; then
        $RM -rf -- rqcfilter2_out
    fi
    if [[ $FILTER == derek-bbduk || $all ]]; then
        $RM -f -- rtrim_fwd.fastq
        $RM -f -- adtrim_clean_fwd.fastq
        $RM -f -- adtrim_clean_rev.fastq
        $RM -f -- adtrim_clean_qtrim_rev.fastq
        $RM -f -- adtrim_clean_qtrim_rev.derep.fastq
        $RM -f -- adtrim_rev.fastq
        $RM -f -- rtrim_rev.fastq
        $RM -f -- phix_clean_stats.txt
        $RM -f -- phix174_ill.ref.fa
        $RM -f -- PhiX_matched.fastq
        $RM -f -- adtrim_fwd.fastq
        $RM -f -- adtrim_clean_qtrim_fwd.fastq
        $RM -f -- adtrim_clean_qtrim_fwd.derep.fastq
    fi
}


if $CLEAN_ONLY; then
    clean_all 
    exit
fi

clean_up () {
    # kill background
    j_long=$(jobs -l)
    if [[ -n $j_long ]]; then
        warning1 "The QC pipeline did not finish properly"
        warning1 "Still running background processes will be terminated, see errors below:"
    fi
    for j in $(jobs -p); do
        error1 "Terminating $(echo "$j_long" | grep "$j")"
        kill -s 15 "$j"
    done
    # clean temp data
    [[ -v tmpd ]] || exit 0
    $KEEPALL || info1 "Erasing intermediate results (keep them with --keep-all)..."
    debug "$(ls -Rlrth "$tmpd")"
    $RM -rf -- "$tmpd"
    rm -rf -- "$tmpd"
    debug "Cleanup done"
}
trap clean_up EXIT

# set up temp dir
declare -i size_reads tmp_avail expected
size_reads=$(stat --print=%s "$FWD_FASTQ")
tmpd=$(mktemp -d)
expected=$((size_reads*20))
tmp_avail=$(df --output=avail "$tmpd" | grep '[0-9]')
tmp_avail=$((tmp_avail*1024))
# fwd input data size in bytes x20 to anticipate ten-fold increase
# compare to available which df delivers in kbytes
if [[ $expected -gt $tmp_avail ]]; then
    warning1 "There may not be sufficient space for your temporary files:"
    warning1 "Available at $tmpd: $tmp_avail bytes, expected need: $expected"
fi
debug "Using temp dir: $tmpd"

# clean up first
clean_some

$MKDIR -p FASTQC
info1 "Starting pre-QC fastqc..."
fastqc -o FASTQC -f fastq -t 2 "$FWD_FASTQ" "$REV_FASTQ" &> FASTQC/fastqc.log &

# basename for files
base=""

# trim_in is what derep puts out, input for trimming

if $DEREPLICATION && [[ $FILTER != bbtools ]] && [[ $FILTER != derek-bbduk ]]; then
    info1 "Starting derep..."
    base=".derep"
    fwd_derep_out=$tmpd/$fwd$base.fastq
    rev_derep_out=$tmpd/$rev$base.fastq

    fwd_trim_in=$fwd_derep_out
    rev_trim_in=$rev_derep_out

    python3 -m omics.derep "${V[@]}" --check "$FWD_FASTQ" "$REV_FASTQ" --out-dir "$tmpd"

    if $KEEPALL; then
        cp -p "${V[@]}" -- "$fwd_derep_out" "$fwd$base.fastq"
        cp -p "${V[@]}" -- "$rev_derep_out" "$rev$base.fastq"
    fi
else
    fwd_trim_in=$FWD_FASTQ
    rev_trim_in=$REV_FASTQ
fi

oldbase=$base
tmp_fwd_final=$tmpd/$fwd.$FINAL.fastq
tmp_rev_final=$tmpd/$rev.$FINAL.fastq
tmp_int_final=$tmpd/int.$FINAL.fastq

if [[ $FILTER == trimmomatic ]]; then
    # Trimmomatic's makes the data streaming more complicated:  It's seems not
    # possible to use fifos as input and it produces four output files that we
    # need to post-process, however with --keep-all the trimmed files are saved
    # directly and then reused for post-processing, hopefully the page-cache
    # makes this efficient
    base="${base}.trim"
    fwd_trim_s=$tmpd/$fwd$base.s.fastq
    rev_trim_s=$tmpd/$rev$base.s.fastq

    info1 "Start adapter + quality trimming..."


    TrimmomaticPE \
        -threads "$CPUS" \
        "$fwd_trim_in" "$rev_trim_in" \
        "$tmp_fwd_final" "$fwd_trim_s" "$tmp_rev_final" "$rev_trim_s" \
        ILLUMINACLIP:"$ADAPTERS":2:30:10:1:true \
        LEADING:3 TRAILING:3 \
        SLIDINGWINDOW:4:20 \
        MINLEN:20

    # re-pair singles
    info1 "Pairing up singles and adding to Trimmomatic output..."
    cat "$fwd_trim_s" >> "$tmp_fwd_final"
    grep -E '^@[^ ]+:[0-9]+:[0-9]+ 1' "$fwd_trim_s" | sed -r 's/ 1/ 2/; s/$/\nN\n+\n!/' >> "$tmp_rev_final"
    cat "$rev_trim_s" >> "$tmp_rev_final"
    grep -E '^@[^ ]+:[0-9]+:[0-9]+ 2' "$rev_trim_s" | sed -r 's/ 2/ 1/; s/$/\nN\n+\n!/' >> "$tmp_fwd_final"

elif [[ $FILTER == scythe ]]; then
    info1 "Start adapter trimming..."
    base="${base}.scythe"
    # scythe_out to be fed into interleaver
    fwd_scythe_out=$tmpd/$fwd$base.fastq
    rev_scythe_out=$tmpd/$rev$base.fastq
    mkfifo "$fwd_scythe_out" "$rev_scythe_out"
    scythe -a "$ADAPTERS" -q sanger -m "$fwd${oldbase}.matches.fastq" -o "$fwd_scythe_out" "$fwd_trim_in" &
    scythe -a "$ADAPTERS" -q sanger -m "$rev${oldbase}.matches.fastq" -o "$rev_scythe_out" "$rev_trim_in" &
    info1 "Start interleaving reads..."
    if $KEEPALL; then
        fwd_int_in=$tmpd/fwd.int_in.fastq
        rev_int_in=$tmpd/rev.int_in.fastq
        mkfifo "$fwd_int_in" "$rev_int_in"
        # shellcheck disable=SC2094
        tee "./$(basename "$fwd_scythe_out")" < "$fwd_scythe_out" > "$fwd_int_in" &
    base="${base}.sickle"
        # shellcheck disable=SC2094
        tee "./$(basename "$rev_scythe_out")" < "$rev_scythe_out" > "$rev_int_in" &
    else
        fwd_int_in=$fwd_scythe_out
        rev_int_in=$rev_scythe_out
    fi
    sickle_in=$tmpd/int$base.fastq
    mkfifo "$sickle_in"
    python3 -m omics.interleave "${V[@]}" "$fwd_int_in" "$rev_int_in" > "$sickle_in" &
    info1 "Start quality score trimming..."
    oldbase=$base
    base="${base}.sickle"
    sickle pe -t sanger -c "$sickle_in" -M "$tmp_int_final"

elif [[ $FILTER == bbtools ]]; then
    base=$base.rqcfilter

    info1 "Running BBTools' QC pipeline..."

    rqcfilter2_out=rqcfilter2_out
    mkdir -p -- "$rqcfilter2_out"
    rqcfilter2_args=(
        in="$fwd_trim_in"
        in2="$rev_trim_in"
        path="$rqcfilter2_out"
        rqcfilterdata="$RQCFILTERDATA"
        barcodefilter=f
        qtrim=rl
        trimq=15
        minlength=20
        threads="$CPUS"
    )
    if $DEREPLICATION; then
        rqcfilter2_args+=(
            clumpify=t
            dedupe=t
            opticaldupes=t
        )
    fi
    rqcfilter2 "${rqcfilter2_args[@]}" |& tee "$rqcfilter2_out"/log
    filtered_fastq=$rqcfilter2_out/$(grep ^filtered_fastq= "$rqcfilter2_out/file-list.txt" | sed 's/filtered_fastq=//')
    gunzip -c "$(realpath "$filtered_fastq")" > "$tmp_int_final"
elif [[ $FILTER == derek-bbduk ]]; then
    base=$base.derek-bbduk
    (
        cd "$tmpd"
        # adapted from Derek's bbmap_qc.sh
        info1 "Removing 3' adapters"
        bbduk in1="$WORK_DIR/$fwd_trim_in" in2="$WORK_DIR/$rev_trim_in" out1="$tmpd"/rtrim_fwd.fastq out2="$tmpd"/rtrim_rev.fastq ref="$RQCFILTERDATA"/adapters2.fa.gz ktrim=r k=21 mink=8 hdist=2 ftm=5 tpe tbo threads="$CPUS"

        # Now Remove 5' adapters, allowing 2 mismatches, trim paired ends to equal length:
        info1 "Removing 5' adapters"
        bbduk in1="$tmpd"/rtrim_fwd.fastq in2="$tmpd"/rtrim_rev.fastq out1="$tmpd"/adtrim_fwd.fastq out2="$tmpd"/adtrim_rev.fastq ref="$RQCFILTERDATA"/adapters2.fa.gz ktrim=l k=21 mink=8 hdist=2 tpe threads="$CPUS"

        # Screen for kmers of length 31 that match PhiX (a standard Illumina spike-in) and remove them from reads:
        info1 "Remove PhiX spike-in reads"
        gunzip -c "$RQCFILTERDATA"/phix174_ill.ref.fa.gz > "$tmpd"/phix174_ill.ref.fa
        bbduk in1="$tmpd"/adtrim_fwd.fastq in2="$tmpd"/adtrim_rev.fastq out1="$tmpd"/adtrim_clean_fwd.fastq out2="$tmpd"/adtrim_clean_rev.fastq outm=PhiX_matched.fastq ref="$RQCFILTERDATA"/phix174_ill.ref.fa.gz k=31 hdist=1 stats=phix_clean_stats.txt threads="$CPUS"
        $RM -f -- "$tmpd"/phix174_ill.ref.fa

        # Trim bases with Phred quality score below 15. After trimming remove reads with length <70 bp:
        info1 "Quality trim bases with Q score below 15"
        bbduk in1="$tmpd"/adtrim_clean_fwd.fastq in2="$tmpd"/adtrim_clean_rev.fastq out1="$tmpd"/adtrim_clean_qtrim_fwd.fastq out2="$tmpd"/adtrim_clean_qtrim_rev.fastq qtrim=rl trimq=15 minlen=75 threads="$CPUS"

        # Dereplicate read pairs that are 100% identical:
        info1 "Deduplicating"
        omics derep $"$tmpd"/adtrim_clean_qtrim_fwd.fastq "$tmpd"/adtrim_clean_qtrim_rev.fastq -o ./ -v
    )

    # interleave and re-establish piping
    info1 "Interleaving trimmed read pairs..."
    omics interleave "${V[@]}" "$tmpd"/adtrim_clean_qtrim_fwd.derep.fastq "$tmpd"/adtrim_clean_qtrim_rev.derep.fastq > "$tmp_int_final"

else
    abort1 "Bad argument for --filter option, available alternatives are: trimmomatic scythe bbtools"
fi

oldbase=$base
base=".$FINAL"
fwd_final=$(basename "$tmp_fwd_final")
rev_final=$(basename "$tmp_rev_final")
int_final=$(basename "$tmp_int_final")

if [[ ! -e $tmp_int_final ]]; then
    # if needed for some filters
    info1 "Interleaving trimmed read pairs..."
    python3 -m omics.interleave --check "${V[@]}" "$tmp_fwd_final" "$tmp_rev_final" > "$tmp_int_final"
fi

cp -p -- "$tmp_int_final" "$int_final" &

if $INTERLEAVE_FASTA; then
    info1 "Start converting to fasta..."
    python3 -m omics.fastq2fasta "${V[@]}" < "$tmp_int_final" > "int.$FINAL.fasta" &
fi

if [[ ! -e "$tmp_fwd_final" || ! -e "$tmp_rev_final" ]]; then
    # as needed for some filter modes
    info1 "Separating read directions..."
    separate-interleaved "${V[@]}" -f "$tmp_fwd_final" -r "$tmp_rev_final" "$tmp_int_final"
fi

{
    cp -p -- "$tmp_fwd_final" "$fwd_final"
    cp -p -- "$tmp_rev_final" "$rev_final"
} &

info1 "Starting post-QC fastqc run..."
fastqc -o FASTQC -f fastq -t 2 "$tmp_fwd_final" "$tmp_rev_final" &>> FASTQC/fastqc.log

# TODO: job waiting code needs re-work after getting rid of most piping

# map cmd-line sub-strings to job description
declare -A wait_list
wait_list=(
[ fastqc ]="FASTQC"
[omics.derep]="dereplication"
[ scythe ]="adapter trimming"
[omics.interleave]="interleaving"
[ sickle ]="quality trimming"
[omics.fastq2fasta]="converting to fasta format"
[separate-interleave]="separating read directions again"
)

# map PIDs to job wait list
declare -A pids
while read -r line; do
    pid=$(echo "$line" | sed -r 's/[ ]+/ /g' | cut -d' ' -f2)
    for i in "${!wait_list[@]}"; do
        if echo "$line" | grep -q "$i"; then
            pids["$pid"]="$i"
            break
        fi
    done
done < <(jobs -l)

# wait for jobs to finish
for p in $(echo "${!pids[@]}" | sed -r 's/ /\n/g' | sort -n); do
    if wait "$p"; then
       info1 "Done: ${wait_list[${pids[$p]}]}"
   else
       error1 "${wait_list[${pids[$p]}]}: exit status $?, PID: $pid"
   fi
done

if $KEEPALL; then
    info1 "Copying intermediate files..."
    find "$tmpd" -type f -print0 | xargs -0 cp "${V[@]}" -n -t ./ --
fi
info1 "All done!"


# gmb: input: fwd.fastq
# gmb: input: rev.fastq
# gmb: output: good_int.fasta
# gmb: cpus: 2
