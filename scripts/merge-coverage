#!/usr/bin/env python3

# Copyright 2019 Regents of The University of Michigan.

# This file is part of geo-omics-scripts.

# Geo-omics-scripts is free software: you can redistribute it and/or
# modify it under the terms of the GNU General Public License as published
# by the Free Software Foundation, either version 3 of the License, or (at
# your option) any later version.

# Geo-omics-scripts is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.

# You should have received a copy of the GNU General Public License along
# with Geo-omics-scripts.  If not, see <https://www.gnu.org/licenses/>.

"""
Make a table of coverage per contig per sample suitable for input to CONCOCT
"""
import argparse
from collections import OrderedDict
from itertools import groupby
from operator import itemgetter
from pathlib import Path
import sys


def read_tsv(file):
    """
    Generate list of list from tab-separated data.

    :param iterable file: Iterable of lines of tab-separated data
    """
    for line in file:
        yield line.strip().split(b'\t')


def main(assembly, outfile, *inputfiles, with_length=False, verbose=False):
    def info(*msg, sep=' ', end='\n'):
        if verbose:
            print(*msg, sep=sep, end=end, file=sys.stderr, flush=True)

    if len(inputfiles) != len(set(inputfiles)):
        # check for non-unique input files
        raise RuntimeError('Found multiple occurrences of some input coverage '
                           'file')

    # generate sample ids from variable parts (if more than one inputfile)
    ids = [list(i.parts) for i in inputfiles]
    if len(ids) > 1:
        while True:
            # strip common prefix
            if len(set([i[0] for i in ids])) == 1:
                ids = [i[1:] for i in ids]
            else:
                break
        while True:
            # strip common suffix
            if len(set([i[-1] for i in ids])) == 1:
                ids = [i[:-1] for i in ids]
            else:
                break
    ids = ['_'.join(i) for i in ids]

    header = ['contig']
    if with_length:
        header.append('length')

    if assembly is None:
        raise RuntimeError('Please provide the assembly, assembly-less '
                           'algorithm is not implemented')

    with assembly.open('rb') as inf:
        info('Reading assembly...', end=' ')
        # get contigs from assembly
        contigs = sorted([
            line.strip().lstrip(b'>').split()[0]
            for line in inf
            if line.startswith(b'>')
        ])

    out_data = OrderedDict([
        (i, {'length': None, 'means': []})
        for i in contigs
    ])
    info('done')

    for path, sample_id in zip(inputfiles, ids):
        with path.open('rb') as inf:
            # check header
            head = [i.decode() for i in inf.readline().strip().split(b'\t')]
            if not head == ['Contig', 'Depth', 'bases_with_depth',
                            'contigLen', 'fraction_bases_with_depth']:
                raise RuntimeError('Unexpected header found in {}'
                                   ''.format(path))

            info('Reading {}... '.format(sample_id), end='')
            header.append(sample_id)

            in_data = {
                    contig: list(it)
                    for contig, it in groupby(
                        sorted(read_tsv(inf), key=itemgetter(0)),
                        itemgetter(0)
                    )
            }

        info('processing... ', end='')
        for contig in out_data:
            if contig in in_data:
                cov_bases = 0
                for line in in_data[contig]:

                    # sanity check
                    if len(line) != 5:
                        raise RuntimeError(
                            'Wrong number of items in line: {}, file: {}'
                            ''.format(line, inf.name)
                        )

                    # more sanity checks
                    try:
                        this_length = int(line[3])
                    except ValueError:
                        raise RuntimeError(
                            'Failed to parse length field, not a number?: '
                            'line: {}, file: {}'.format(line, path)
                        )

                    if out_data[contig]['length'] is None:
                        # set length for contig
                        out_data[contig]['length'] = this_length
                    else:
                        if this_length != out_data[contig]['length']:
                            raise RuntimeError(
                                'Unexpected contig length found: {}\nwhole '
                                'line: {}\nfile: {}'
                                ''.format(line[3], line, path)
                            )

                    try:
                        cov_bases += int(line[1]) * int(line[2])
                    except ValueError:
                        raise RuntimeError(
                            'Field contents is not a number: line: {}, file: '
                            '{}'.format(line, path)
                        )

                # add mean coverage
                out_data[contig]['means'].append(cov_bases / this_length)
            else:
                out_data[contig]['means'].append(0.0)
        info('done')

    if len(header[2:]) != len(set(header[2:])):
        raise RuntimeError('Ambiguous sample identifiers: {}'
                           ''.format(header[2:]))

    info('Writing output...', end='')
    print(*header, sep='\t', file=outfile)
    for contig, contig_data in out_data.items():
        out_line = [contig.decode()]
        if with_length:
            out_line.append(contig_data['length'] or 0)
        out_line += ['{:.6f}'.format(i) for i in contig_data['means']]
        print(*out_line, sep='\t', file=outfile, flush=False)
    outfile.flush()
    info('done')


if __name__ == '__main__':
    argp = argparse.ArgumentParser(description=__doc__)
    argp.add_argument(
        '-a', '--assembly',
        metavar='ASSEMBLY',
        nargs='?',
        default=None,
        help='The assembly file.  This is to be compatible with the CONCOCT '
             'workflow.  If used then contigs not covered by any sample will '
             'appear in the output with zeros (unlike the output of bedtool\'s'
             ' genomeCoverageBed.)'
    )
    argp.add_argument(
        'inputfiles',
        metavar='INFILE',
        nargs='+',
        help='List of input coverage files, on per sample. '
             'The variable parts of these paths are used as'
             'sample identifier.'
    )
    argp.add_argument(
        '-o', '--out',
        metavar='OUTFILE',
        nargs='?',
        type=argparse.FileType('w'),
        default=sys.stdout,
        help='Output file. By default stdout is used.'
    )
    argp.add_argument(
        '--debug',
        action='store_true',
        help='Print stack trace on errors.'
    )
    argp.add_argument(
        '--length',
        action='store_true',
        help='Insert column with contig length. The default is not to insert '
             'lengths.'
    )
    argp.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Report progress to stderr.'
    )
    args = argp.parse_args()

    try:
        if args.length:
            print('WARNING: using assembly file, length of not covered contigs'
                  ' is not shown correctly. (implementation missing)',
                  file=sys.stderr)
        main(
            Path(args.assembly),
            args.out,
            *[Path(i) for i in args.inputfiles],
            with_length=args.length,
            verbose=args.verbose,
        )
    except Exception as e:
        if args.debug:
            raise
        else:
            print(
                'An error occurred: {}: {}'.format(e.__class__.__name__, e),
                file=sys.stderr,
            )
            sys.exit(1)
